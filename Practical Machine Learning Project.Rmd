---
title: "Practical Machine Learning Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview  

As large volume of data is being generated by Human Activity Recognition tools, there is need to analyse this dataset and get quantified results. As part of the project, we were supplied with data collected by accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. So that people can quantify how much of a particular activity they do, as well as how well they do it.
For this exercise, we have given two datasets one for trainig our prediction model and other to evaluate our model amd mahe predictions.  

 * <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv> [Training Dataset]  
 * <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>  [Testing Dataset]  

## Load Library  

Lets first, load all required packages. 

```{r libs, warning=FALSE,message=FALSE}
library(caret)
```

## Data Processing and cleansing:  
 First acquire data from source website and load in our variables. then cleanse it by removing irrelevent variables and variables with most NA entries.  
 
```{r tidy,warning=FALSE}

train_dtset<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",na.strings = c("NA",""))
test_dtset<- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",na.strings = c("NA",""))

#Remove NA columns
schema_nm<-names(train_dtset)
NA_cols<-c()
for (i in 1:length(train_dtset))
{
  na_ratio<-(length(which(is.na(train_dtset[,schema_nm[i]])==T))/length(train_dtset[,schema_nm[i]]))
  if (na_ratio > 0.90)
  {
    NA_cols<-c(NA_cols,i)
  }
}
training_dataset<- train_dtset[,-c(NA_cols)]
# Remove irrelevant fields
training_dataset<- training_dataset[,-c(1:7)]
dim(training_dataset)
names(training_dataset)

```
  
Now Apply same transformation to Testing Dataset.  
```{r format_testdata,warning=FALSE}
col_name<-colnames(training_dataset[,-c(length(training_dataset))]) # remove outcome column
testing_dataset<- test_dtset[,col_name]
dim(testing_dataset)
names(testing_dataset)
```  
  
  
## Data Spltting and fitting a model    

We have large amount of data for training and less number of records to testing, So to improve out of sample error, we will split training set into two sets, 80% to train and 20%. We will first build model using 80% dataset and then apply it on 20% dataset to check if its accuracy is less than acceptable. If accuracy is less,we to make adjustment for out of sample error.  
For building prediction model we will use cross-validation with 3 folds and then apply random forest method.   

```{r DT_SPLIT,warning=FALSE}
set.seed(500)
rec_split <- createDataPartition(y=training_dataset$classe, p=0.8, list=F)
training_subset1 <- training_dataset[rec_split, ]
training_subset2 <- training_dataset[-rec_split, ]

train_seting <- trainControl(method="cv", number=3, verboseIter=F)
train_seting
fit <- train(classe ~ ., data=training_subset1, method="rf", trControl=train_seting)

```

Lets Apply this model to get predictions on second training set and check confusion matrix  for accuracy.  

```{r train2_predict,warning=FALSE}
predicts <- predict(fit, newdata=training_subset2)
confusionMatrix(training_subset2$classe, predicts)
```
 As accuracy is more than 99%, lets not go to do additional correction for out of sample error.  
  
## Re-training the Selected Model  
Now, lets apply this model on entire training set to ge final fitted model for prediction.  
  
```{r train_entire,warning=FALSE}
TR_Control <- trainControl(method="cv", number=3, verboseIter=F)
final_fit <- train(classe ~ ., data=training_dataset, method="rf", trControl=TR_Control)
```

## Generate Prediction    
  Applying new model to testing dataset to get final predictions.  
  
```{r test_evol,warning=FALSE}
test_predicts <- predict(final_fit, newdata=testing_dataset)
test_predicts
```


